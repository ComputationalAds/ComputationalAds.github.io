
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>计算广告与机器学习</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="ZhouYong">
    

    
    <meta name="description" content="机器学习预估系统与算法模型以CTR预估为例

预估算法系统综述
预估系统架构 
广告算法预估模块
CTR, CVR, 交易额，ROI等 




预估算法模型
大规模稀疏模型
Boosting模型
Embedding+NN模型
Wide&amp;amp;Deep
DeepFM
DIN


DNN+用户行为序列
DIEN
DSIN




预估算法工程
大数据处理框架
特征抽取框架 
离线训练框架
在线预估">
<meta property="og:type" content="article">
<meta property="og:title" content="计算广告与机器学习">
<meta property="og:url" content="http://www.52caml.com/deep_learning/dl-chapter10-ctrcvr/index.html">
<meta property="og:site_name" content="计算广告与机器学习">
<meta property="og:description" content="机器学习预估系统与算法模型以CTR预估为例

预估算法系统综述
预估系统架构 
广告算法预估模块
CTR, CVR, 交易额，ROI等 




预估算法模型
大规模稀疏模型
Boosting模型
Embedding+NN模型
Wide&amp;amp;Deep
DeepFM
DIN


DNN+用户行为序列
DIEN
DSIN




预估算法工程
大数据处理框架
特征抽取框架 
离线训练框架
在线预估">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="计算广告与机器学习">
<meta name="twitter:description" content="机器学习预估系统与算法模型以CTR预估为例

预估算法系统综述
预估系统架构 
广告算法预估模块
CTR, CVR, 交易额，ROI等 




预估算法模型
大规模稀疏模型
Boosting模型
Embedding+NN模型
Wide&amp;amp;Deep
DeepFM
DIN


DNN+用户行为序列
DIEN
DSIN




预估算法工程
大数据处理框架
特征抽取框架 
离线训练框架
在线预估">

    
    <link rel="alternative" href="/atom.xml" title="计算广告与机器学习" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="计算广告与机器学习" title="计算广告与机器学习"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="计算广告与机器学习">计算广告与机器学习</a></h1>
				<h2 class="blog-motto">Computational Advertising and Machine Learning</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/home">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:www.52caml.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/deep_learning/dl-chapter10-ctrcvr/" title="" itemprop="url"></a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="ZhouYong" target="_blank" itemprop="author">ZhouYong</a>
		
  <p class="article-time">
    <time datetime="2020-03-19T01:36:17.000Z" itemprop="datePublished"> 发表于 2020-03-19</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习预估系统与算法模型"><span class="toc-number">1.</span> <span class="toc-text">机器学习预估系统与算法模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1.预估算法模型"><span class="toc-number">2.</span> <span class="toc-text">预估算法模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1.3.Embedding+NN模型"><span class="toc-number">2.1.</span> <span class="toc-text">Embedding+NN模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.1.WideAndDeep"><span class="toc-number">2.1.1.</span> <span class="toc-text">Wide&Deep</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.2.DeepFM"><span class="toc-number">2.1.2.</span> <span class="toc-text">DeepFM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.3.DIN"><span class="toc-number">2.1.3.</span> <span class="toc-text">DIN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.4.DIEN"><span class="toc-number">2.1.4.</span> <span class="toc-text">DIEN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.5.DSIN"><span class="toc-number">2.1.5.</span> <span class="toc-text">DSIN</span></a></li></ol></li></ol></li></ol>
		
		</div>
		
		<h1 id="机器学习预估系统与算法模型">机器学习预估系统与算法模型</h1><p>以CTR预估为例</p>
<ul>
<li><a href="#0.预估算法系统综述">预估算法系统综述</a><ul>
<li><a href="#0.2.预估系统架构">预估系统架构</a> </li>
<li><a href="#0.3.广告算法预估模块">广告算法预估模块</a><ul>
<li>CTR, CVR, 交易额，ROI等 </li>
</ul>
</li>
</ul>
</li>
<li><a href="#1.预估算法模型">预估算法模型</a><ul>
<li><a href="#1.1">大规模稀疏模型</a></li>
<li><a href="#1.2">Boosting模型</a></li>
<li><a href="#1.3.Embedding+NN模型">Embedding+NN模型</a><ul>
<li><a href="#1.3.1.WideAndDeep">Wide&amp;Deep</a></li>
<li><a href="#1.3.2.DeepFM">DeepFM</a></li>
<li><a href="#1.3.3.DIN">DIN</a></li>
</ul>
</li>
<li><a href="#1.4.DNN+用户行为序列">DNN+用户行为序列</a><ul>
<li><a href="#1.4.1.DIEN">DIEN</a></li>
<li><a href="#1.4.2.DSIN">DSIN</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2.预估算法工程">预估算法工程</a><ul>
<li><a href="#2.1.大数据处理框架">大数据处理框架</a></li>
<li><a href="#2.2.特征抽取框架">特征抽取框架</a> </li>
<li><a href="#2.3.离线训练框架">离线训练框架</a></li>
<li><a href="#2.4.在线预估服务">在线预估服务</a></li>
</ul>
</li>
</ul>
<h1 id="1.预估算法模型">预估算法模型</h1>


<h2 id="1.3.Embedding+NN模型">Embedding+NN模型</h2>

<p>TODO，介绍该类模型特点</p>
<h3 id="1.3.1.WideAndDeep">Wide&amp;Deep</h3>

<p>Wide&amp;Deep模型是Google于2016年在DLRS会议上发表的文章《Wide&amp;Deep Learning for Recommender System》。文中设计了一种<strong>融合浅层模型（wide）和深层模型（deep）进行联合训练的框架，综合浅层模型的记忆能力（wide）和DNN模型的泛化能力，从而提升模型整体性能</strong>。</p>
<blockquote>
<p>该模型成功应用在Google Play的app推荐业务中，并取得下载率3.9%的提升。线上性能通过batch size分包，多线程并行调用（处理）达到提升效率的目的，单次响应耗时由31ms降至14ms。 </p>
</blockquote>
<p>从用户体验的角度讲，搜索、推荐、广告都存在的一个挑战是如何通过获得返回结果的准确性和扩展性。更多时候，最好的状态是二者兼顾，不可偏废。</p>
<blockquote>
<ol>
<li>如果返回结果都是精准内容（与用户历史强相关），那么易造成用户兴趣收敛，无新鲜感，不利于用户长久留存，同时浪费了流量价值；</li>
<li>如果返回结果内容过于泛化，用户的精准兴趣无法得到满足，用户体验欠佳，流失风险较大。</li>
</ol>
</blockquote>
<p>因此，相对于准确性，扩展性倾向于改善返回结果的多样性。</p>
<p>另外，从机器学习模型能力的角度讲，模型能力的核心就是其表达能力，而表达能力可以从两个方面解读，即模型的记忆能力和泛化能力。更多时候，表达能力也需要在二者之间平衡。</p>
<blockquote>
<ol>
<li>过度追求模型的记忆能力，易造成模型过拟合。因为我们可以用很复杂的模型或设计复杂的特征来拟合训练样本，但是在测试数据上表现不一定好；</li>
<li>过度追求模型泛化能力，会出现模型表达能力不够，使得模型区分性差。在推荐场景下可能无法真正做法个性化推荐；在广告CTR预估场景，过于泛化的模型影响预估的精准度，继而影响计费等；</li>
</ol>
</blockquote>
<ul>
<li><strong>记忆能力（Memorization）</strong></li>
</ul>
<p>超大规模稀疏机器学习模型的特征体系通常离不开人工设计的组合特征（又叫交叉特征，cross-product）。通过设计二阶或高阶组合特征可以描述稀疏特征之间的关联性（这里特指共现性），基于此训练得到的模型可以很好的记忆历史数据中曾经共现过的组合特征信息。</p>
<p>传统超大规模稀疏模型如LR、FFM等，特征工程两个主要思路：</p>
<ol>
<li>离散特征：基于原始离散特征，设计2阶或高阶组合特征，如<code>user-item</code>, <code>request-item</code>, <code>user-request-item</code>等；</li>
<li>连续特征：做特征离散化，之后当作离散特征训练大规模稀疏模型。</li>
</ol>
<p>以上方法的优点是实现快速高效、特征重要性易分析、模型可解释性高等，在我们广告CTR预估系统证明非常有效（以FFM模型为例，亿级别特征，10GB+模型）</p>
<blockquote>
<p>模型效果比较：高维稀疏特征+LR模型 &amp;&amp; 低维连续特征+GBDT模型，在广告CTR核心广告位，auc／rps指标前者好于后者均在5%以上；</p>
</blockquote>
<p>人工设计特征这一点不能作为传统大规模稀疏模型的缺点，因为特征工程方面的工作本身就包涵了特征设计本身，这一点与具体模型关系不大。另外，个人经验，相对传统预估模型，DNN模型对特征工程的要求更高（因为特征种类更复杂，特征尺度要保持一致，如连续特征归一化等）。</p>
<p><strong>记忆能力的缺点：易出现过拟合</strong>。设计更加稀疏or更复杂的模型理论上可以无限拟合训练样本，但是也易出现模型的泛化能力较差在测试集表现不好。解决该问题的方法通常有：</p>
<ol>
<li>稀疏特征频次过滤（通过设定阈值），训练样本不包含小于阈值的稀疏特征；</li>
<li>模型训练时，优化目标加上L1惩罚项或使用FTRL优化算法等，得到模型的稀疏表示。</li>
</ol>
<ul>
<li><strong>泛化能力（Generialization）</strong></li>
</ul>
<p>在WDL文章中，对于泛化能力的理解是：为sparse特征学习低维的dense embedding用来表示特征相关性（Deep层的输入可以包含sparse特征和dense特征）。</p>
<p>泛化能力的优点是可以减少人工组合特征，对历史上没有出现的特征组合有一定的泛化性（类似FM）。但是物极必反，当<code>&lt;user,item&gt;</code>非常稀疏时，例如有和独特偏好的users以及很小众的items，DNN很难为users和items学习到有效的embedding。这种情况下，大部分<code>&lt;user,item&gt;</code>应该是没有关联的，但dense embedding 的方法还是可以得到对所有<code>&lt;user,item&gt;</code> pair 的非零预测，因此导致 过于泛化（over-generalize）并推荐无相关性的内容，准确性得不到保证。此时Memorization就展示了优势，它可以“记住”这些特殊的特征组合。</p>
<p>Memorization根据历史行为数据，返回的结果通常和用户已有行为的直接相关的item。而Generalization会学习新的特征模式，提高推荐item的多样性。 论文作者结合两者的优点，提出了一个新的学习算法——Wide&amp;Deep Learning，其中Wide、Deep分别对应Memorization、Generalization。</p>
<ul>
<li><strong>模型结构</strong></li>
</ul>
<p><strong>TODO 用DL工具画图</strong></p>
<p>模型表达式为：</p>
<p>$$<br>P(y=1|x) = \sigma\left(W_{wide}^T [x, \phi(x)] + W_{deep}^T \mathcal{a}^{(l_f)} + b \right) = \sigma\left(y_{\text{LR}} + y_{\text{DNN}} \right)<br>$$</p>
<p>其中，$\mathcal{a}^{(l_f)} = f(W^{(l-1)} \mathcal{a}^{(l-1)} + b^{(l-1)})$</p>
<ol>
<li>Wide部分：广义线性模型；</li>
<li>Deep部分：sparse特征输入学习低维embedding（embedding层），之后多层全连接，如果有dense特征，在全连接前与embedding输出concat在一起；</li>
<li>损失函数：交叉熵损失；</li>
<li>模型训练：论文中wide部分FTRL，deep部分AdaGrad算法；</li>
</ol>
<h3 id="1.3.2.DeepFM">DeepFM</h3>

<p>DeepFM是2017年华为发表在IJCAI会议上的一篇文章《DeepFM: A Factorization-Machine based Neural Network for CTR Prediction》提出的模型。</p>
<p>DeepFM模型的初衷同样是强化特征之间的交互关系，比如<code>&lt;饭点儿，外卖&gt;</code>反映了时间特征与item类别之间的关系。除此之外，还有其它的特征组合关系，有些很容易想到，有些因为不符合我们平时的认知不容易想出来。怎么办呢？当然是希望机器可以帮助我们自动学到很多特征之间的关系。</p>
<p>DeepFM模型结构融合了FM和DNN两部分，前者负责二阶组合特征的学习，后者侧重于高阶特征的学习。这两部分共享embedding层。因此DeepFM模型结构可以理解为：</p>
<p>$$<br>P(y=1|x) = \sigma \left(y_{\text{FM}} + y_{\text{DNN}} \right)<br>$$</p>
<blockquote>
<p>关于FM／FFM模型在<a href="http://www.52caml.com/head_first_ml/ml-chapter9-factorization-family/" target="_blank" rel="external">第09章：深入浅出ML之Factorization家族</a>中有详细的解读。</p>
</blockquote>
<p><strong>DeepFM vs FNN vs PNN</strong></p>
<ol>
<li>DeepFM: FM+DNN并行结构；</li>
<li>FNN: FN,DNN串行结构。FM模型先训练好embedding，然后作为DNN的输入；</li>
<li>PNN: 在embedding层与FC层添加了product操作（内积或外积），之后与原始的embedding层concat后作为FC的输入；</li>
</ol>
<p>总结DeepFM：FM和DNN共享embedding，同时学习模型二阶和高阶信息。</p>
<h3 id="1.3.3.DIN">DIN</h3>

<p>结合下述问题，先睹为快：</p>
<ol>
<li>DIN激活单元是如何工作的？是self-attention的实现吗？ 答：不是self-attention，<code>&lt;item, ad&gt;</code>向量作为输入，计算外积之后与两个原向量concat后进入一层FC，使用dice作为激活函数，输出1维值作为激活权重；</li>
<li>用户行为A,B,C分别点击了3次、1次、2次，那么广告D如何与用户行为作attention操作，是与ABC做attention，还是A,A,A,B,C,C做attention？文章没有提到，不过可以获取A、B、C次数作为权重，在item embedding后给予加权。</li>
<li>dice激活函数在tf中的实现？对PRelu的改进，</li>
<li>自适应正则在tf中的实现？</li>
</ol>
<p>DIN模型关键词：<strong>兴趣多样性（diversity interests），局部激活单元（local activation unit），mini-batch aware正则，自适应损失函数（Dice）</strong></p>
<ul>
<li><strong>局部激活单元（local activation unit）</strong></li>
</ul>
<p>用户兴趣是多样的，传统DNN模型用户兴趣特征表示为一个定长的向量，与具体的候选ad无关。但实际上，不同的ad与用户兴趣中某些部分是相关的，与另外一些兴趣可能不相关，“只有与ad相关的那部分兴趣”才是有意义的。因此文章主要针对不同的ad，动态地表示用户兴趣。做法是对不同的ad计算用户兴趣中的item的权重，从而实现用户兴趣特征的差异性表达。用户兴趣表达式如下：<br>$$<br>V_U(A) = f(V_A, e_1, e_2, \cdots, e_H) = \sum_{j=1}^H a(e_j, V_A) e_j = \sum_{j=1}^H w_j e_j<br>$$</p>
<p>公式中$a(e_j, V_A)$是一个前馈网络，输出对应的激活权重，其计算过程如下：</p>
<ol>
<li>Out Product：$<e_j, v_a="">$计算外积，得到等长的向量$V_p$。外积操作有利于relevance modeling；</e_j,></li>
<li>Concat：tf.concat([$e_j, V_A, V_P$], axis=1, keepdims=false)</li>
<li>PRelu或Dice：激活函数，这里有一层FC参数（W,b）?</li>
<li>Linear：转化为1维作为activation weight；</li>
</ol>
<p>这里的局部激活单元计算方法有别于传统attention，它放宽了权重累加和等于1（$\sum w_j = 1$）的限制条件，$w_j$有利于表达用户兴趣的差异化强度。因此无需对$a(e_j, V_A)$使用softmax归一化。</p>
<ul>
<li><strong>自适应激活函数（Dice）</strong></li>
</ul>
<p>PRelu函数的rectified point（校正点）是固定的0，这在每一层的输入分布发生变化时是不适用的，所以文章对该激活函数进行了改进，提出Dice激活函数，平滑了rectified point附近曲线的同时，<strong>Dice会根据每层输入数据的分布来自适应调整rectified point的位置</strong>。</p>
<p>PRelu激活函数表达式：</p>
<p>$$<br>f(x) =<br>\begin{cases}<br>\displaystyle<br>x &amp; \text{if x &gt; 0}, \\\<br>\alpha x &amp; \text{if x } \leq 0<br>\end{cases}<br>\longrightarrow<br>f(x)  = p(x) \cdot x + (1 - p(x)) \cdot \alpha x \quad<br>p(x) = I(x)   \quad // p(x) 是指示函数<br>$$<br>Dice函数的$p(x)$表达式不是指示函数，而是：<br>$$<br>p(x) = \frac{1} { 1 + \exp{ \left(- \frac{x - E(x)} {\sqrt{Var(x) + \epsilon} } \right) } }<br>$$</p>
<p>计算输入x的均值和方差，动态调整，$\epsilon=1e^{-8}$。</p>
<blockquote>
<p>Dice函数对模型效果的影响。列表：auc+0.1%；搜索：无提升</p>
</blockquote>
<ul>
<li><strong>mini-batch aware正则方法</strong></li>
</ul>
<p>// TODO</p>
<p><strong>DIN总结</strong></p>
<p>Base模型相比，DIN建模思想反映在模型结构上，差别主要体现在<strong>如何聚合多个用户行为Embedding向量</strong>，DIN建模考虑了用户兴趣的多样性，以及针对不同目标item，用户历史行为发挥的作用（weight）也是有差异的（局部激活）。</p>
<ol>
<li>Base模型中直接对多个Embedding向量进行等权的sum-pooling，这种方法肯定会带来信息的丢失，而且相对重要的Embedding向量也无法完全突出自己所包含的信息。DIN采取了一个比较直观的方式，就是weighted-sum pooling，而且Attention的本质也可以认为是weighted-sum，让模型更加关注有用的信息（有用信息的权重会更大一些）；</li>
<li>DIN不足：DIN仍然是直接把“用户行为”直接作为“兴趣”特征feed给模型，没有考虑<strong>兴趣具有动态性及演化漂移</strong>的特点，所以<strong>DIN抽取的兴趣之间是独立无关联的，不能捕获到兴趣的动态演进性</strong>。</li>
</ol>
<p>基于DIN存在的不足，DIN团队又提出了升级版模型－DIEN模型。</p>
<h3 id="1.3.4.DIEN">DIEN</h3>

<ol>
<li>如何表示输入？ID和属性类结合？</li>
<li></li>
</ol>
<p>DIEN关键词：兴趣动态性；兴趣漂移；兴趣抽取层（Interest Extractor）；兴趣演化层（Interest Evolution）；</p>
<p><strong>背景</strong></p>
<p>深度兴趣演进网络（Deep Interest Evolution Network，简称DIEN）的提出主要是为了解决非搜索场景下，如果通过设计模型来更好的捕获用户的动态变化的兴趣。</p>
<p><strong>DIEN模型特点</strong></p>
<ol>
<li>提出一个新的网络结构对<strong>用户兴趣演化过程</strong>进行建模，提升兴趣表达能力。</li>
<li><strong>兴趣抽取层</strong>。与直接把行为序列作为兴趣特征喂给模型不同，DIEN设计了特征抽取层，针对GRU的兴趣状态在表达用户兴趣时缺少指导目标，作者提出了<strong>辅助Loss</strong>的方法，辅助Loss利用连续的行为在每一步去监督学习隐含兴趣状态，从而让<strong>隐含兴趣状态更好的表达隐含兴趣</strong>。</li>
<li><strong>兴趣演进层</strong>。将GRU升级为AUGRU（Attention Update GRU）加强了兴趣与目标之间的相关性，目的是<strong>克服由兴趣漂移带来的预估不准的问题</strong>。</li>
</ol>
<p><strong>DIEN模型结构</strong></p>
<p>DIN与DIEN底层都是Embedding层，基础特征的处理方式是一致的。不同的是，DIEN将用户行为组织成了序列数据的形式，并把简单的使用out product完成的activation unit变成了attention-based GRU网路。</p>
<p>_兴趣抽取层（Interest Extractor Layer）_</p>
<p>兴趣抽取层的目标是<strong>从embedding数据中提取出兴趣状态信息</strong>。但是一个用户在某一时间的兴趣不仅与当前的behavior有关，也与之前的behavior相关，所以作者使用GRU单元提取一系列兴趣状态。</p>
<blockquote>
<p>GRU克服了RNN梯度消失问题，同时快于LSTM，综合考量选择GRU。</p>
</blockquote>
<p>GRU表达式为：</p>
<p>TODO </p>
<blockquote>
<p>更详细的GRU解读参考系列总结<a href="">sss</a></p>
</blockquote>
<p>如何评估GRU提取出的用户兴趣是否合理，是否准确？文中引入了辅助loss，通过监督学习来提升兴趣表达的准确性。</p>
<p>这里，作者设计了一个二分类模型来计算兴趣抽取的准确性，将用户下一时刻真实的行为$e_{t+1}$作为正例，负采样得到的行为作为负例，用$e_{t+1}^{’}$表示，分别与抽取出来的兴趣$h_t$结合输入到辅助网络中，得到预测结果，并通过logloss计算一个辅助损失。公式如下：</p>
<blockquote>
<p><strong>问题</strong>：特征抽取层引入GRU的目的是认为兴趣与当前行为有关，与之前行为也有关；引入辅助loss是为了监督学习兴趣的状态表达。那么既然这里的GRU和辅助loss都是为了更准确的学习兴趣表示，并且建模过程中已经用了当前行为的前后信息，为啥还要有下文_兴趣进化层_的必要性呢？</p>
</blockquote>
<p>TODO</p>
<p>_兴趣进化层（Interest Evolution Layer）_</p>
<p>兴趣进化层的目标是刻画用户兴趣的进化过程，该层结构是AUGRU。建模用户兴趣进化过程有两方面好处：</p>
<ol>
<li>追踪用户的interest可以使我们学习final interest的表达时包含更多的历史信息；</li>
<li>可以根据interest的变化趋势更好的进行CTR预测。（怎么证明？？）</li>
</ol>
<p>兴趣变化过程中有两点规律： </p>
<ol>
<li>兴趣漂移（interest shift）：用户在某一段时间的interest有一定的集中性，兴趣之间有一定的跳跃；</li>
<li>兴趣独立（interest individual）：不同种类的interest之间很少相互影响；</li>
</ol>
<p>参考：对比传统作业，直接把行为序列作为兴趣特征喂给模型；</p>
<h3 id="1.3.5.DSIN">DSIN</h3>

<p>深度会话兴趣网络（Deep Session Interest Network）</p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://www.52caml.com/deep_learning/dl-chapter10-ctrcvr/" data-title="计算广告与机器学习" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/deep_learning/dl-chapter9-recall-algorithm/"  title="">
 <strong>下一篇：</strong><br/> 
 <span>(no title)
</span>
</a>
</div>

</nav>

	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习预估系统与算法模型"><span class="toc-number">1.</span> <span class="toc-text">机器学习预估系统与算法模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1.预估算法模型"><span class="toc-number">2.</span> <span class="toc-text">预估算法模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1.3.Embedding+NN模型"><span class="toc-number">2.1.</span> <span class="toc-text">Embedding+NN模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.1.WideAndDeep"><span class="toc-number">2.1.1.</span> <span class="toc-text">Wide&Deep</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.2.DeepFM"><span class="toc-number">2.1.2.</span> <span class="toc-text">DeepFM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.3.DIN"><span class="toc-number">2.1.3.</span> <span class="toc-text">DIN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.4.DIEN"><span class="toc-number">2.1.4.</span> <span class="toc-text">DIEN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1.3.5.DSIN"><span class="toc-number">2.1.5.</span> <span class="toc-text">DSIN</span></a></li></ol></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/OpenMIT/" title="OpenMIT">OpenMIT<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/分布式机器学习/" title="分布式机器学习">分布式机器学习<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/强化学习与智能决策/" title="强化学习与智能决策">强化学习与智能决策<sup>4</sup></a></li>
		  
		
		  
			<li><a href="/categories/概率与统计/" title="概率与统计">概率与统计<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/深入浅出机器学习/" title="深入浅出机器学习">深入浅出机器学习<sup>9</sup></a></li>
		  
		
		  
			<li><a href="/categories/深度学习/" title="深度学习">深度学习<sup>6</sup></a></li>
		  
		
		  
			<li><a href="/categories/计算广告学/" title="计算广告学">计算广告学<sup>2</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Attention/" title="Attention">Attention<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/计算广告学/" title="计算广告学">计算广告学<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Agent/" title="Agent">Agent<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/参数服务器/" title="参数服务器">参数服务器<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/反向传播/" title="反向传播">反向传播<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Softmax/" title="Softmax">Softmax<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Pooling/" title="Pooling">Pooling<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Policy-Iteration/" title="Policy Iteration">Policy Iteration<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Value-Iteration/" title="Value Iteration">Value Iteration<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Greedy-Policy/" title="Greedy Policy">Greedy Policy<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/连续随机变量/" title="连续随机变量">连续随机变量<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/MDP/" title="MDP">MDP<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Markov-Decision-Process/" title="Markov Decision Process">Markov Decision Process<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/RL/" title="RL">RL<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Environments/" title="Environments">Environments<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/GD/" title="GD">GD<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/FTRL/" title="FTRL">FTRL<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/AdaGrad/" title="AdaGrad">AdaGrad<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/AdaDelta/" title="AdaDelta">AdaDelta<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Adam/" title="Adam">Adam<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, Welcome to CAML technology sharing platform.  <br/>
			I&#39;m Zhou Yong, engaged in algorithms work on computational advertising and machine learning.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/1707438033" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/ComputationalAds" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		
		
		<a href="mailto:zhouyongsdzh@foxmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2020 
		
		<a href="/about" target="_blank" title="ZhouYong">ZhouYong</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#nothing"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>









<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
